{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a6f28092",
   "metadata": {
    "id": "a6f28092"
   },
   "source": [
    "## üß† LangGraph Agent with GPT-4o-mini, Tool, and Short-Term Memory\n",
    "In this notebook, you'll learn how to build a simple AI agent equipped with a toold and short memory using LangGraph and OpenAI's GPT-4o-mini."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce3ba82",
   "metadata": {
    "id": "dce3ba82"
   },
   "source": [
    "### üîß Step 1: Install Required Packages\n",
    "We run the following cell to install the necessary packages. We‚Äôre making sure LangChain, LangGraph, and the OpenAI wrapper are on the latest version so every API we call later is available. The -U flag upgrades anything that‚Äôs already installed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8abff58b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 26886,
     "status": "ok",
     "timestamp": 1750668981781,
     "user": {
      "displayName": "Ana RE",
      "userId": "12917217046164012432"
     },
     "user_tz": -60
    },
    "id": "8abff58b",
    "outputId": "eb216f70-e114-4c0b-e470-cc7f9181cbad"
   },
   "outputs": [],
   "source": [
    "!pip install -U langchain langgraph langchain-openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b25f2b90",
   "metadata": {
    "id": "b25f2b90"
   },
   "source": [
    "### üîë Step 2: Set Your OpenAI API Key\n",
    "\n",
    "The agent will talk to OpenAI‚Äôs GPT-4o-mini model hosted in Azure OpenAI. Azure OpenAI uses the same models as OpenAI but allows with a different endpoint. Putting your key and endpoint in environment variables lets every downstream cell authenticate automatically without hard-coding secrets into the notebook.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "567ab4ff",
   "metadata": {
    "id": "567ab4ff"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "12e2feb1",
   "metadata": {
    "id": "12e2feb1"
   },
   "source": [
    "### ü§ñ Step 3: Import Required Libraries\n",
    "\n",
    "Here we pull in the building blocks:\n",
    "\n",
    "* `from langchain_openai import AzureChatOpenAI:` This brings in the AzureChatOpenAI class.\n",
    "It lets you use OpenAI's chat models (like GPT-3.5 or GPT-4) in your app.\n",
    "\n",
    "* `from langchain.agents import create_agent:` This imports a helper function to quickly build an AI agent. The agent uses the ReAct framework: it can reason about a question and then act using tools (like calling a function).\n",
    "It saves you from writing a lot of setup code.\n",
    "\n",
    "* `from langgraph.graph.message import MessagesState:` This class helps track the conversation. It keeps a record of all the messages exchanged between the user and the agent. Useful for managing context in a conversation.\n",
    "\n",
    "* `from langchain_core.messages import HumanMessage:` This represents a message from a human. You use it to tell the agent, ‚ÄúThis is what the user said.‚Äù\n",
    "\n",
    "* `from langchain_core.runnables import RunnableConfig:` This is used to configure how the agent runs.\n",
    "\n",
    "* `from langgraph.checkpoint.memory import InMemorySaver:` This sets up a memory system that stores conversation history in memory. It helps the agent remember what was said earlier in the same session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae59a2b",
   "metadata": {
    "id": "cae59a2b"
   },
   "outputs": [],
   "source": [
    "from langchain_openai import AzureChatOpenAI\n",
    "from langchain.agents import create_agent\n",
    "from langgraph.graph.message import MessagesState\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "from langgraph.checkpoint.memory import InMemorySaver"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34faeaf0",
   "metadata": {
    "id": "34faeaf0"
   },
   "source": [
    "### üß† Step 4: Load the GPT-4o-mini Model\n",
    "\n",
    "`AzureChatOpenAI` gives us a convenient Python object that wraps the GPT-4o-mini API. Setting `temperature=0.7` makes answers a little more creative while still fairly reliable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f49a0c4",
   "metadata": {
    "id": "9f49a0c4"
   },
   "outputs": [],
   "source": [
    "llm = AzureChatOpenAI(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    temperature=0.7\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "VNgwU9VocQVc",
   "metadata": {
    "id": "VNgwU9VocQVc"
   },
   "source": [
    "### üß† Step 5: Create a Memory Saver\n",
    "\n",
    "`InMemorySaver()` is LangGraph‚Äôs simplest ‚Äúcheckpoint‚Äù store. Whenever the agent finishes a turn, it drops the final graph state here, which lets future calls pick up the same conversation thread."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "JbXDxsUcb3gs",
   "metadata": {
    "id": "JbXDxsUcb3gs"
   },
   "outputs": [],
   "source": [
    "checkpointer = InMemorySaver()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "diFg6wE9cuZL",
   "metadata": {
    "id": "diFg6wE9cuZL"
   },
   "source": [
    "### üî® Step 6: Define a Tool\n",
    "\n",
    "This toy tool `get_animaltype` pretends to reach out to some knowledge base, but really just echoes a canned fact. The point is to show how tools can be implemented. The agent can decide when to call a tool, pass it arguments, and then weave its output back into the reply."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fWAuPlnb6R8",
   "metadata": {
    "id": "7fWAuPlnb6R8"
   },
   "outputs": [],
   "source": [
    "def get_animaltype(animal: str) -> str:\n",
    "    \"\"\"Get type of animal simulation tool.\"\"\"\n",
    "    return f\"{animal} have four legs!\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76qDrrzSdJIl",
   "metadata": {
    "id": "76qDrrzSdJIl"
   },
   "source": [
    "### üïµÔ∏è Step 7: Define Agent\n",
    "\n",
    "`create_agent` wires everything together using the ReAct pattern. The agent can think step-by-step, optionally call get_animaltype, remember context via the checkpoint-based memory, and then output a final answer‚Äîall in one execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "s1FGPGxnb8Pa",
   "metadata": {
    "id": "s1FGPGxnb8Pa"
   },
   "outputs": [],
   "source": [
    "agent = create_agent(\n",
    "    model=llm,\n",
    "    tools=[get_animaltype],\n",
    "    checkpointer=checkpointer\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "TGfDjDAgdPxe",
   "metadata": {
    "id": "TGfDjDAgdPxe"
   },
   "source": [
    "### ‚öôÔ∏è Step 8: Run the Agent\n",
    "\n",
    "The config dictionary gives LangGraph a thread_id. Any turn that uses the same ID re-hydrates the stored memory so the agent ‚Äúremembers‚Äù the earlier chat. Swap in a new ID to start a completely fresh conversation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hYd0pVLiRnoQ",
   "metadata": {
    "id": "hYd0pVLiRnoQ"
   },
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"configurable\": {\n",
    "        \"thread_id\": \"1\"\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4L7XaFo0dkmt",
   "metadata": {
    "id": "4L7XaFo0dkmt"
   },
   "source": [
    "### üß™ Step 9: Test the Agent\n",
    "\n",
    "1.\tFirst call ‚Äì We ask ‚ÄúHow many legs do cats have?‚Äù The agent chooses to call the tool, gets back the canned fact, and responds.\n",
    "2.\tSecond call ‚Äì With the same thread_id, we ask about dogs. Because the earlier exchange is stored in memory, the agent sees full context and can keep the dialogue flowing naturally.\n",
    "3.\tPrinting the agent's reponse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "l-5o1oHlcA1D",
   "metadata": {
    "id": "l-5o1oHlcA1D"
   },
   "outputs": [],
   "source": [
    "cat_response = agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"How many legs cats have?\"}]},\n",
    "    config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "NG0qyfnSdbgd",
   "metadata": {
    "id": "NG0qyfnSdbgd"
   },
   "outputs": [],
   "source": [
    "# Continue the conversation using the same thread_id\n",
    "dog_response = agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"What about dogs?\"}]},\n",
    "    config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "D8MSZLhBrVB-",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1750669560966,
     "user": {
      "displayName": "Ana RE",
      "userId": "12917217046164012432"
     },
     "user_tz": -60
    },
    "id": "D8MSZLhBrVB-",
    "outputId": "5e70df55-a76d-4444-8417-642f0f7f4053"
   },
   "outputs": [],
   "source": [
    "first_response = cat_response[\"messages\"][-1]\n",
    "print(\"Agent:\", first_response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Q1Qf5O0JT1ka",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1750669588819,
     "user": {
      "displayName": "Ana RE",
      "userId": "12917217046164012432"
     },
     "user_tz": -60
    },
    "id": "Q1Qf5O0JT1ka",
    "outputId": "3541bbe2-0304-4506-8dc4-0a3c982a7368"
   },
   "outputs": [],
   "source": [
    "second_response = dog_response[\"messages\"][-1]\n",
    "print(\"Agent:\", second_response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec19c40b",
   "metadata": {},
   "source": [
    "## What's Next\n",
    "\n",
    "Click the Jupyter logo in the upper-left corner to open the file tree view and try applying what you've learned in the `Activity.ipynb` notebook."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [
    {
     "file_id": "1gfVs_EyX7nbkFtq3E2vDeQw-Wj544kRs",
     "timestamp": 1749735297577
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
